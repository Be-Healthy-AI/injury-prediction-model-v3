#!/usr/bin/env python3
"""Prepare daily feature subsets for retrospective backtesting.

This script copies existing daily feature CSVs for selected players into
`backtests/daily_features/`, trimming the rows to the requested date ranges.
"""
from __future__ import annotations

import argparse
from pathlib import Path
from typing import Dict, Tuple

import pandas as pd

import sys

ROOT_DIR = Path(__file__).resolve().parents[2]
if str(ROOT_DIR) not in sys.path:
    sys.path.append(str(ROOT_DIR))

from scripts.backtests.config_utils import BacktestEntry, load_backtest_config  # noqa: E402

# Default player windows (player_id: (start_date, end_date))
DEFAULT_WINDOWS: Dict[int, Tuple[str, str]] = {
    452607: ("2025-01-01", "2025-02-08"),  # Alexander Bah
    699592: ("2025-01-01", "2025-02-08"),  # Manu Silva
    258027: ("2025-09-01", "2025-10-29"),  # Renato Sanches
    8198: ("2025-04-01", "2025-05-11"),  # Cristiano Ronaldo
    200512: ("2024-04-01", "2024-05-31"),  # Sadio ManÃ©
}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--config",
        type=Path,
        default=None,
        help="Optional JSON backtesting configuration generated by build_window_config.py.",
    )
    parser.add_argument(
        "--windows",
        type=str,
        default=None,
        help=(
            "Optional custom windows in the format "
            "player_id:start:end,player_id:start:end ... "
            "(dates in YYYY-MM-DD)."
        ),
    )
    parser.add_argument(
        "--source-dir",
        type=Path,
        default=Path("daily_features_output"),
        help="Directory containing the full daily feature CSVs.",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("backtests") / "daily_features",
        help="Directory to write the trimmed daily feature CSVs to.",
    )
    parser.add_argument(
        "--pre-days",
        type=int,
        default=34,
        help=(
            "Number of days before the requested start date to include in the subset "
            "to ensure 35-day windows can be generated (default: 34)."
        ),
    )
    return parser.parse_args()


def parse_windows(raw: str | None) -> Dict[int, Tuple[str, str]]:
    if not raw:
        return DEFAULT_WINDOWS

    windows: Dict[int, Tuple[str, str]] = {}
    for item in raw.split(","):
        parts = item.strip().split(":")
        if len(parts) != 3:
            raise ValueError(f"Invalid window specification: {item!r}")
        player_id, start, end = parts
        windows[int(player_id)] = (start, end)
    return windows


def trim_daily_features(
    player_id: int,
    start: str,
    end: str,
    source_dir: Path,
    output_dir: Path,
    pre_days: int,
) -> Path:
    src_file = source_dir / f"player_{player_id}_daily_features.csv"
    if not src_file.exists():
        raise FileNotFoundError(f"Missing source file: {src_file}")

    df = pd.read_csv(src_file)
    if "date" not in df.columns:
        raise KeyError(f"Column 'date' not found in {src_file}")

    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    start_ts = pd.to_datetime(start) - pd.Timedelta(days=pre_days)
    end_ts = pd.to_datetime(end)
    mask = (df["date"] >= start_ts) & (df["date"] <= end_ts)
    subset = df.loc[mask].copy().sort_values("date")

    output_dir.mkdir(parents=True, exist_ok=True)
    dst_file = output_dir / (
        f"player_{player_id}_daily_features_{start.replace('-', '')}_{end.replace('-', '')}.csv"
    )
    subset.to_csv(dst_file, index=False, encoding="utf-8-sig")
    return dst_file


def trim_daily_features_for_entry(
    entry: BacktestEntry,
    source_dir: Path,
    output_dir: Path,
) -> Path:
    src_file = source_dir / f"player_{entry.player_id}_daily_features.csv"
    if not src_file.exists():
        raise FileNotFoundError(f"Missing source file: {src_file}")

    df = pd.read_csv(src_file)
    if "date" not in df.columns:
        raise KeyError(f"Column 'date' not found in {src_file}")

    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    mask = (df["date"] >= entry.history_start) & (df["date"] <= entry.history_end)
    subset = df.loc[mask].copy().sort_values("date")
    if subset.empty:
        raise ValueError(
            f"No daily feature rows found for entry {entry.entry_id} "
            f"between {entry.history_start.date()} and {entry.history_end.date()}"
        )

    output_dir.mkdir(parents=True, exist_ok=True)
    dst_file = output_dir / entry.daily_features_filename
    subset.to_csv(dst_file, index=False, encoding="utf-8-sig")
    return dst_file


def main() -> None:
    args = parse_args()
    if args.config:
        entries = load_backtest_config(args.config)
        print(f"Preparing daily feature subsets using config: {args.config}")
        for entry in entries:
            try:
                dst_file = trim_daily_features_for_entry(
                    entry=entry,
                    source_dir=args.source_dir,
                    output_dir=args.output_dir,
                )
            except Exception as exc:  # pylint: disable=broad-except
                print(f"[WARN] {entry.entry_id}: {exc}")
                continue
            else:
                print(f"[OK] {entry.entry_id}: saved to {dst_file}")
        return

    windows = parse_windows(args.windows)

    print("Preparing daily feature subsets...")
    for player_id, (start, end) in windows.items():
        try:
            dst_file = trim_daily_features(
                player_id,
                start,
                end,
                args.source_dir,
                args.output_dir,
                pre_days=args.pre_days,
            )
        except Exception as exc:  # pylint: disable=broad-except
            print(f"[WARN] Player {player_id}: {exc}")
            continue
        else:
            print(f"[OK] Player {player_id}: saved to {dst_file}")


if __name__ == "__main__":
    main()
