#!/usr/bin/env python3
"""Generate 35-day timelines for retrospective backtesting.

This script reuses the production timeline logic to create inference-ready
35-day windows for specific players and date ranges. The resulting CSVs are
stored under `backtests/timelines/` and can be consumed by prediction scripts.
"""
from __future__ import annotations

import argparse
from pathlib import Path
from typing import Dict, Iterable, Tuple

import pandas as pd

# Ensure project root is on sys.path so we can import production utilities
import sys

ROOT_DIR = Path(__file__).resolve().parents[2]
if str(ROOT_DIR) not in sys.path:
    sys.path.append(str(ROOT_DIR))

# Import the production timeline utilities
from scripts.create_35day_timelines_v3 import (  # type: ignore
    create_windowed_features_vectorized,
    build_timeline,
    get_player_name,
)
from scripts.backtests.config_utils import BacktestEntry, load_backtest_config

DEFAULT_WINDOWS: Dict[int, Tuple[str, str]] = {
    452607: ("2025-01-01", "2025-02-08"),  # Alexander Bah
    699592: ("2025-01-01", "2025-02-08"),  # Manu Silva
    258027: ("2025-09-01", "2025-10-29"),  # Renato Sanches
    8198: ("2025-04-01", "2025-05-11"),  # Cristiano Ronaldo
    200512: ("2024-04-01", "2024-05-31"),  # Sadio ManÃ©
}

WINDOW_SIZE_DAYS = 35
BUFFER_DAYS = WINDOW_SIZE_DAYS - 1  # 34 days


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--config",
        type=Path,
        default=None,
        help="Optional JSON backtesting configuration generated by build_window_config.py.",
    )
    parser.add_argument(
        "--windows",
        type=str,
        default=None,
        help=(
            "Optional custom windows in the format "
            "player_id:start:end,player_id:start:end ... "
            "(dates in YYYY-MM-DD)."
        ),
    )
    parser.add_argument(
        "--daily-features-dir",
        type=Path,
        default=Path("backtests") / "daily_features",
        help="Directory containing the trimmed daily feature CSVs.",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("backtests") / "timelines",
        help="Directory to write the generated timeline CSVs to.",
    )
    return parser.parse_args()


def parse_windows(raw: str | None) -> Dict[int, Tuple[str, str]]:
    if not raw:
        return DEFAULT_WINDOWS

    windows: Dict[int, Tuple[str, str]] = {}
    for item in raw.split(","):
        parts = item.strip().split(":")
        if len(parts) != 3:
            raise ValueError(f"Invalid window specification: {item!r}")
        player_id, start, end = parts
        windows[int(player_id)] = (start, end)
    return windows


def iter_reference_dates(start: pd.Timestamp, end: pd.Timestamp) -> Iterable[pd.Timestamp]:
    current = start
    while current <= end:
        yield current
        current += pd.Timedelta(days=1)


def generate_timelines_for_player(
    player_id: int,
    start: str,
    end: str,
    daily_features_dir: Path,
    output_dir: Path,
) -> Path:
    file_pattern = f"player_{player_id}_daily_features_{start.replace('-', '')}_{end.replace('-', '')}.csv"
    src_file = daily_features_dir / file_pattern
    if not src_file.exists():
        raise FileNotFoundError(
            f"Daily features subset not found for player {player_id}: {src_file}"
        )

    df = pd.read_csv(src_file)
    if "date" not in df.columns:
        raise KeyError(f"Column 'date' not found in {src_file}")

    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df.sort_values("date", inplace=True)
    df.reset_index(drop=True, inplace=True)

    available_dates = set(df["date"].dropna())
    player_name = get_player_name(player_id)

    start_ts = pd.to_datetime(start)
    end_ts = pd.to_datetime(end)

    timelines = []

    for reference_date in iter_reference_dates(start_ts, end_ts):
        if reference_date not in available_dates:
            continue
        window_start = reference_date - pd.Timedelta(days=BUFFER_DAYS)
        if window_start not in available_dates:
            # Ensure we have full 35-day history
            continue

        window_features = create_windowed_features_vectorized(df, window_start, reference_date)
        if window_features is None:
            continue

        ref_row = df.loc[df["date"] == reference_date].iloc[0]
        timeline = build_timeline(
            player_id=player_id,
            player_name=player_name,
            reference_date=reference_date,
            ref_row=ref_row,
            windowed_features=window_features,
            target=0,  # target is irrelevant for inference but required by the schema
        )
        timelines.append(timeline)

    if not timelines:
        raise ValueError(f"No valid timelines generated for player {player_id} between {start} and {end}")

    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / f"player_{player_id}_timelines_{start.replace('-', '')}_{end.replace('-', '')}.csv"
    pd.DataFrame(timelines).to_csv(output_file, index=False, encoding="utf-8-sig")
    return output_file


def generate_timelines_for_entry(
    entry: BacktestEntry,
    daily_features_dir: Path,
    output_dir: Path,
) -> Path:
    src_file = daily_features_dir / entry.daily_features_filename
    if not src_file.exists():
        raise FileNotFoundError(
            f"Daily features subset not found for entry {entry.entry_id}: {src_file}"
        )

    df = pd.read_csv(src_file)
    if "date" not in df.columns:
        raise KeyError(f"Column 'date' not found in {src_file}")

    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df.sort_values("date", inplace=True)
    df.reset_index(drop=True, inplace=True)

    available_dates = set(df["date"].dropna())
    player_name = get_player_name(entry.player_id)

    timelines = []
    for reference_date in iter_reference_dates(entry.window_start, entry.window_end):
        if reference_date not in available_dates:
            continue
        window_start = reference_date - pd.Timedelta(days=BUFFER_DAYS)
        if window_start not in available_dates:
            # Ensure we have full 35-day history
            continue

        window_features = create_windowed_features_vectorized(df, window_start, reference_date)
        if window_features is None:
            continue

        ref_row = df.loc[df["date"] == reference_date].iloc[0]
        timeline = build_timeline(
            player_id=entry.player_id,
            player_name=player_name,
            reference_date=reference_date,
            ref_row=ref_row,
            windowed_features=window_features,
            target=0,
        )
        timeline["entry_id"] = entry.entry_id
        timelines.append(timeline)

    if not timelines:
        raise ValueError(
            f"No valid timelines generated for entry {entry.entry_id} "
            f"between {entry.window_start.date()} and {entry.window_end.date()}"
        )

    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / entry.timelines_filename
    pd.DataFrame(timelines).to_csv(output_file, index=False, encoding="utf-8-sig")
    return output_file


def main() -> None:
    args = parse_args()
    if args.config:
        entries = load_backtest_config(args.config)
        print(f"Generating 35-day timelines using config: {args.config}")
        for entry in entries:
            try:
                output_file = generate_timelines_for_entry(
                    entry=entry,
                    daily_features_dir=args.daily_features_dir,
                    output_dir=args.output_dir,
                )
            except Exception as exc:  # pylint: disable=broad-except
                print(f"[WARN] {entry.entry_id}: {exc}")
                continue
            else:
                print(f"[OK] {entry.entry_id}: timelines saved to {output_file}")
        return

    windows = parse_windows(args.windows)

    print("Generating 35-day timelines for backtesting...")
    for player_id, (start, end) in windows.items():
        try:
            output_file = generate_timelines_for_player(
                player_id,
                start,
                end,
                daily_features_dir=args.daily_features_dir,
                output_dir=args.output_dir,
            )
        except Exception as exc:  # pylint: disable=broad-except
            print(f"[WARN] Player {player_id}: {exc}")
            continue
        else:
            print(f"[OK] Player {player_id}: timelines saved to {output_file}")


if __name__ == "__main__":
    main()
